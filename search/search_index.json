{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"MLDocs \ud83d\udcc3 MLDocs is a convenient, searchable, waffle-free, cheatsheet-like website which covers foundational and more technically in-depth machine learning code and equations. In going through various online courses, books and technical docs, I quickly discovered the need for a resource to provide a handy reference to refer back to. Machine learning is a complex subject with many moving parts - it can be intimidating and easy to forget things sometimes! Any algorithms and explanations given are intended to be as concise as possible. Where relevant, code examples and links to Google Colab notebooks will be provided. This is an ever-growing site and is actively maintained! The accompanying GitHub repo behind this site is ml-resources .","title":"Home"},{"location":"#mldocs","text":"MLDocs is a convenient, searchable, waffle-free, cheatsheet-like website which covers foundational and more technically in-depth machine learning code and equations. In going through various online courses, books and technical docs, I quickly discovered the need for a resource to provide a handy reference to refer back to. Machine learning is a complex subject with many moving parts - it can be intimidating and easy to forget things sometimes! Any algorithms and explanations given are intended to be as concise as possible. Where relevant, code examples and links to Google Colab notebooks will be provided. This is an ever-growing site and is actively maintained! The accompanying GitHub repo behind this site is ml-resources .","title":"MLDocs \ud83d\udcc3"},{"location":"algorithms/linear-regression/","text":"Linear regression models take the following form: \\[ y = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... + \\theta_n x_n \\] To train the regression model, we can use the Mean Square Error performance metric to find the parameters which minimise the error: \\[ \\mathrm{MSE}(\\boldsymbol{\\theta}) = \\frac{1}{m}\\sum^m_{i=1}(\\boldsymbol{\\theta}^{\\mathrm{T}} \\mathbf{x}^{(i)} - y^{(i)})^2 \\] We can use the Normal Equation (closed-form solution) to find \\(\\boldsymbol{\\theta}\\) (i.e. the parameters which minimise the MSE): \\[ \\boldsymbol{\\hat{\\theta}} = (\\boldsymbol{\\mathrm{X}}^{\\mathrm{T}} \\boldsymbol{\\mathrm{X}})^{-1} \\boldsymbol{\\mathrm{X}}^{\\mathrm{T}} \\boldsymbol{\\mathrm{y}} \\] Implementation import pandas as pd import numpy as np def concat_ones ( X ): # Adds a column of 1's to the matrix X n_items = X . shape [ 0 ] X_b = np . c_ [ np . ones (( n_items , 1 )), X ] # add x0 = 1 to each instance return X_b def lr_normal_train ( X , y ): # Uses the Normal Equation to compute parameters for Linear Regression n_items = X . shape [ 0 ] X_b = concat_ones ( X ) theta_best = np . linalg . inv ( X_b . T . dot ( X_b )) . dot ( X_b . T ) . dot ( y ) return theta_best Normal Equation Complexity In practice, it is best to avoid using the Normal Equation due to the computational complexity ( \\(\\mathrm{O}(\\mathrm{n}^3)\\) ) of inverting the matrix \\(\\boldsymbol{\\mathrm{X}}\\) . This means doubling the number of features increases computation time by \\(2^3 = 8\\) times. Goodness of fit (sum of squares of deviations of fit from the data): \\[ \\chi^2 = \\sum_i r_i^2 = \\sum_i (y_i - mx_i - c)^2 \\] Want to minimise \\(\\chi^2\\) , so differentiate and set to 0: \\[ \\begin{equation} \\nabla \\chi^2=\\left[\\begin{array}{l} \\frac{\\partial \\chi^2}{\\partial m} \\\\ \\frac{\\partial \\chi^2}{\\partial c} \\end{array}\\right]=\\left[\\begin{array}{l} -2 \\sum_i x_i\\left(y_i-m x_i-c\\right) \\\\ -2 \\sum_i\\left(y_i-m x_i-c\\right) \\end{array}\\right]=\\left[\\begin{array}{l} 0 \\\\ 0 \\end{array}\\right] \\end{equation} \\] After some algebra we get: \\[ \\begin{equation} \\begin{array}{ll} m=\\frac{\\sum(x-\\bar{x}) y}{\\sum(x-\\bar{x})^2} & \\sigma_m^2 \\simeq \\frac{\\chi^2}{\\sum_i(x_i-\\bar{x})^2(n-2)} \\\\ c=\\bar{y}-m \\bar{x} & \\sigma_c \\simeq \\sigma_m \\sqrt{\\bar{x}^2+\\frac{1}{n} \\sum_i(x_i-\\bar{x})^2} \\end{array} \\end{equation} \\]","title":"Linear Regression"},{"location":"algorithms/linear-regression/#implementation","text":"import pandas as pd import numpy as np def concat_ones ( X ): # Adds a column of 1's to the matrix X n_items = X . shape [ 0 ] X_b = np . c_ [ np . ones (( n_items , 1 )), X ] # add x0 = 1 to each instance return X_b def lr_normal_train ( X , y ): # Uses the Normal Equation to compute parameters for Linear Regression n_items = X . shape [ 0 ] X_b = concat_ones ( X ) theta_best = np . linalg . inv ( X_b . T . dot ( X_b )) . dot ( X_b . T ) . dot ( y ) return theta_best Normal Equation Complexity In practice, it is best to avoid using the Normal Equation due to the computational complexity ( \\(\\mathrm{O}(\\mathrm{n}^3)\\) ) of inverting the matrix \\(\\boldsymbol{\\mathrm{X}}\\) . This means doubling the number of features increases computation time by \\(2^3 = 8\\) times.","title":"Implementation"},{"location":"algorithms/linear-regression/#_1","text":"Goodness of fit (sum of squares of deviations of fit from the data): \\[ \\chi^2 = \\sum_i r_i^2 = \\sum_i (y_i - mx_i - c)^2 \\] Want to minimise \\(\\chi^2\\) , so differentiate and set to 0: \\[ \\begin{equation} \\nabla \\chi^2=\\left[\\begin{array}{l} \\frac{\\partial \\chi^2}{\\partial m} \\\\ \\frac{\\partial \\chi^2}{\\partial c} \\end{array}\\right]=\\left[\\begin{array}{l} -2 \\sum_i x_i\\left(y_i-m x_i-c\\right) \\\\ -2 \\sum_i\\left(y_i-m x_i-c\\right) \\end{array}\\right]=\\left[\\begin{array}{l} 0 \\\\ 0 \\end{array}\\right] \\end{equation} \\] After some algebra we get: \\[ \\begin{equation} \\begin{array}{ll} m=\\frac{\\sum(x-\\bar{x}) y}{\\sum(x-\\bar{x})^2} & \\sigma_m^2 \\simeq \\frac{\\chi^2}{\\sum_i(x_i-\\bar{x})^2(n-2)} \\\\ c=\\bar{y}-m \\bar{x} & \\sigma_c \\simeq \\sigma_m \\sqrt{\\bar{x}^2+\\frac{1}{n} \\sum_i(x_i-\\bar{x})^2} \\end{array} \\end{equation} \\]","title":""},{"location":"algorithms/pca/","text":"Principal Component Analysis scikit-learn from sklearn.decomposition import PCA import numpy as np X = np . array ([[ - 1 , - 1 ], [ - 2 , - 1 ], [ - 3 , - 2 ], [ 1 , 1 ], [ 2 , 1 ], [ 3 , 2 ]]) pca = PCA ( n_components = 2 ) pca . fit ( X ) print ( f 'Explained variance ratio: { pca . explained_variance_ratio_ } ' ) print ( f 'Singular values: { pca . singular_values_ } ' ) References: sklearn docs","title":"PCA"},{"location":"algorithms/pca/#principal-component-analysis","text":"scikit-learn from sklearn.decomposition import PCA import numpy as np X = np . array ([[ - 1 , - 1 ], [ - 2 , - 1 ], [ - 3 , - 2 ], [ 1 , 1 ], [ 2 , 1 ], [ 3 , 2 ]]) pca = PCA ( n_components = 2 ) pca . fit ( X ) print ( f 'Explained variance ratio: { pca . explained_variance_ratio_ } ' ) print ( f 'Singular values: { pca . singular_values_ } ' ) References: sklearn docs","title":"Principal Component Analysis"},{"location":"courses/dls/","text":"Deep Learning Specialisation Course 1: Neural Networks and Deep Learning Handwritten Notes \ud83d\udcd5 Course 2: Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization On this page you will find summary notes for key concepts covered in the second course of Coursera's Deep Learning Specialisation by Andrew Ng. The course coveres Hyperparameter Tuning, Regularisation and Optimisation of Deep Neural Networks. Note This page acts as a handy reference (cheatsheet) and is not intended to provide in-depth explanations. However, code snippets and links to external resources will be provided. Train/Dev/Test Sets Applied machine learning is highly iterative. We may need to try out many different models, with each having a large number of possible hyperparameter settings. Given a dataset, we generally split the data into 3 subsets: Training set : used to learn the parameters of a model. Development/validation set : used to rank models following training (tuning hyperparameter settings) so we can choose the best performing model on this set. Test set : used to evaluate the performance of the chosen model and give an unbiased estimate of performance. This helps us assess how well our trained model generalises to unseen data. To create these sets, we can utilise scikit-learn's train_test_split function: Basic Helper Function from sklearn.model_selection import train_test_split X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = 0.2 , random_state = 1 ) X_train , X_val , y_train , y_val = train_test_split ( X_train , y_train , test_size = 0.25 , random_state = 1 ) #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; } Tips Depending on the size of the dataset, a ratio of 60% train/20% dev/20% test can be used, although this can be adjusted accordingly (for very large datasets, a ratio of 98% train/1% dev/1% test would allow the majority of the data to be learned by a model during training, and would allow the dev and test sets to contain enough data to be evaluated on). Shuffle the data randomly to prevent biased results. Not having a dev set would make it difficult to know whether the choice of parameters or choice of model is preventing you from improving the accuracy of your model. If no hyperparameter tuning is required, you may not require a dev set. Ensure the distribution of the dev/test sets match the distribution of the future data (otherwise the model may not work!) Be careful of a mismatched train/test distribution. Forget the test data exists until the very end for a final evaluation and do not tune the model further! References Everything You Need To Know About Train/Dev/Test Split \u2014 What, How and Why ( https://snji-khjuria.medium.com/everything-you-need-to-know-about-train-dev-test-split-what-how-and-why-6ca17ea6f35 ) Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization ( https://www.coursera.org/learn/deep-neural-network?specialization=deep-learning )","title":"Deep Learning Specialisation"},{"location":"courses/dls/#deep-learning-specialisation","text":"","title":"Deep Learning Specialisation"},{"location":"courses/dls/#course-1-neural-networks-and-deep-learning","text":"Handwritten Notes \ud83d\udcd5","title":"Course 1: Neural Networks and Deep Learning"},{"location":"courses/dls/#course-2-improving-deep-neural-networks-hyperparameter-tuning-regularization-and-optimization","text":"On this page you will find summary notes for key concepts covered in the second course of Coursera's Deep Learning Specialisation by Andrew Ng. The course coveres Hyperparameter Tuning, Regularisation and Optimisation of Deep Neural Networks. Note This page acts as a handy reference (cheatsheet) and is not intended to provide in-depth explanations. However, code snippets and links to external resources will be provided.","title":"Course 2: Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization"},{"location":"courses/dls/#traindevtest-sets","text":"Applied machine learning is highly iterative. We may need to try out many different models, with each having a large number of possible hyperparameter settings. Given a dataset, we generally split the data into 3 subsets: Training set : used to learn the parameters of a model. Development/validation set : used to rank models following training (tuning hyperparameter settings) so we can choose the best performing model on this set. Test set : used to evaluate the performance of the chosen model and give an unbiased estimate of performance. This helps us assess how well our trained model generalises to unseen data. To create these sets, we can utilise scikit-learn's train_test_split function: Basic Helper Function from sklearn.model_selection import train_test_split X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = 0.2 , random_state = 1 ) X_train , X_val , y_train , y_val = train_test_split ( X_train , y_train , test_size = 0.25 , random_state = 1 ) #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; } Tips Depending on the size of the dataset, a ratio of 60% train/20% dev/20% test can be used, although this can be adjusted accordingly (for very large datasets, a ratio of 98% train/1% dev/1% test would allow the majority of the data to be learned by a model during training, and would allow the dev and test sets to contain enough data to be evaluated on). Shuffle the data randomly to prevent biased results. Not having a dev set would make it difficult to know whether the choice of parameters or choice of model is preventing you from improving the accuracy of your model. If no hyperparameter tuning is required, you may not require a dev set. Ensure the distribution of the dev/test sets match the distribution of the future data (otherwise the model may not work!) Be careful of a mismatched train/test distribution. Forget the test data exists until the very end for a final evaluation and do not tune the model further! References Everything You Need To Know About Train/Dev/Test Split \u2014 What, How and Why ( https://snji-khjuria.medium.com/everything-you-need-to-know-about-train-dev-test-split-what-how-and-why-6ca17ea6f35 ) Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization ( https://www.coursera.org/learn/deep-neural-network?specialization=deep-learning )","title":"Train/Dev/Test Sets"},{"location":"equations/norms/","text":"Norms \\(L_p\\) Norm Computes the size/length/magnitude of a vector \\[ \\ell_p = \\left(\\sum^N_{i=1} |x_i|^p \\right)^{1/p}, \\text{for } p \\geq 1 \\] Implementation NumPy From Scratch import numpy as np a = np . array ([ 1 , 2 , 3 , 4 , 5 ]) // L1 Norm l1_norm = np . linalg . norm ( a , ord = 1 ) // L2 Norm ( Euclidean norm ) l2_norm = np . linalg . norm ( a , ord = 2 ) // Squared L2 Norm l2_norm_sq = np . linalg . norm ( a , ord = 2 ) ** 2 l2_norm_sq = a . T . dot ( a ) // L \u221e Norm ( Max Norm ) linf_norm = np . linalg . norm ( a , ord = np . inf ) linf_norm = np . max ( np . abs ( a )) a = [ 1 , 2 , 3 , 4 , 5 ] // L1 Norm l1_norm = sum ( abs ( num ) for num in a ) // L2 Norm ( Euclidean norm ) l2_norm = sum ([ num ** 2 for num in a ]) ** 0.5 // Squared L2 Norm l2_norm_sq = sum ([ num ** 2 for num in a ]) // L \u221e Norm ( Max Norm ) linf_norm = max ( abs ( num ) for num in a ) NumPy reference for norms","title":"Norms"},{"location":"equations/norms/#norms","text":"","title":"Norms"},{"location":"equations/norms/#l_p-norm","text":"Computes the size/length/magnitude of a vector \\[ \\ell_p = \\left(\\sum^N_{i=1} |x_i|^p \\right)^{1/p}, \\text{for } p \\geq 1 \\] Implementation NumPy From Scratch import numpy as np a = np . array ([ 1 , 2 , 3 , 4 , 5 ]) // L1 Norm l1_norm = np . linalg . norm ( a , ord = 1 ) // L2 Norm ( Euclidean norm ) l2_norm = np . linalg . norm ( a , ord = 2 ) // Squared L2 Norm l2_norm_sq = np . linalg . norm ( a , ord = 2 ) ** 2 l2_norm_sq = a . T . dot ( a ) // L \u221e Norm ( Max Norm ) linf_norm = np . linalg . norm ( a , ord = np . inf ) linf_norm = np . max ( np . abs ( a )) a = [ 1 , 2 , 3 , 4 , 5 ] // L1 Norm l1_norm = sum ( abs ( num ) for num in a ) // L2 Norm ( Euclidean norm ) l2_norm = sum ([ num ** 2 for num in a ]) ** 0.5 // Squared L2 Norm l2_norm_sq = sum ([ num ** 2 for num in a ]) // L \u221e Norm ( Max Norm ) linf_norm = max ( abs ( num ) for num in a ) NumPy reference for norms","title":"\\(L_p\\) Norm"},{"location":"maths/linear-algebra/","text":"Vectors Size of a vector (modulus): \\[ |\\textbf{r}|= \\sqrt{\\sum_{i=1}^{n} r_i^2} \\] Dot product of two vectors: \\[ \\textbf{r}.\\textbf{s} = \\sum_{i=1}^{n} r_1 s_1 + r_2 s_2 + ... + r_n s_n \\] The dot product is: Commutative: \\(\\textbf{r}.\\textbf{s} = \\textbf{s}.\\textbf{r}\\) Distributive over addition: \\(\\textbf{r}.(\\textbf{s}+\\textbf{t}) = \\textbf{r}.\\textbf{s} + \\textbf{r}.\\textbf{t}\\) Associative over scalar multiplication: \\(\\textbf{r}.(a \\textbf{s}) = a (\\textbf{r}.\\textbf{s})\\) \\[ \\textbf{r}.\\textbf{r} = \\sum_{i=1}^n r_i^2 = \\left(\\sqrt{\\sum_{i=1}^{n} r_i^2}\\right)^2 = |\\textbf{r}|^2 \\] i.e. the size of a vector is the square root of the dot product of the vector with itself. From the cosine rule : \\[ \\textbf{r}.\\textbf{s}=|\\textbf{r}||\\textbf{s}|\\cos \\theta \\] which tells us the extent to which the vectors go in the same direction. Therefore using the dot product, we can get the angle between the two vectors. If: \\(\\theta = 0^{\\circ}, \\cos \\theta = 1, \\therefore \\textbf{r}.\\textbf{s} = |\\textbf{r}||\\textbf{s}|\\) \\(\\theta = 90^{\\circ}, \\cos \\theta = 0, \\therefore \\textbf{r}.\\textbf{s} = 0\\) (vectors are orthogonal) \\(\\theta = 180^{\\circ}, \\cos \\theta = -1, \\therefore \\textbf{r}.\\textbf{s} = -|\\textbf{r}||\\textbf{s}|\\) Scalar Projection Scalar projection of \\(\\textbf{s}\\) onto \\(\\textbf{r}\\) (how much \\(\\textbf{s}\\) goes along \\(\\textbf{r}\\) ): \\[ \\frac{\\textbf{r}.\\textbf{s}}{|\\textbf{r}|} = |\\textbf{s}| \\cos \\theta \\] The scalar projection is 0 if the vectors are orthogonal. Vector Projection \\[ \\textbf{r} \\frac{\\textbf{r}.\\textbf{s}}{|\\textbf{r}||\\textbf{r}|} = \\textbf{r} \\frac{\\textbf{r}.\\textbf{s}}{\\textbf{r}.\\textbf{r}} \\] which is the unit length vector \\(\\frac{\\textbf{r}}{|\\textbf{r}|} \\times\\) scalar projection of \\(\\textbf{s}\\) onto \\(\\textbf{r}\\) . The triangle inequality states that the sum of any two sides of a triangle must be greater than or equal to the size of the remaining side. For every pair of vectors \\(\\textbf{a}\\) and \\(\\textbf{b}\\) : \\[ |\\textbf{a}| + |\\textbf{b}| \\geq |\\textbf{a}+\\textbf{b}| \\]","title":"Linear Algebra"},{"location":"maths/linear-algebra/#vectors","text":"Size of a vector (modulus): \\[ |\\textbf{r}|= \\sqrt{\\sum_{i=1}^{n} r_i^2} \\] Dot product of two vectors: \\[ \\textbf{r}.\\textbf{s} = \\sum_{i=1}^{n} r_1 s_1 + r_2 s_2 + ... + r_n s_n \\] The dot product is: Commutative: \\(\\textbf{r}.\\textbf{s} = \\textbf{s}.\\textbf{r}\\) Distributive over addition: \\(\\textbf{r}.(\\textbf{s}+\\textbf{t}) = \\textbf{r}.\\textbf{s} + \\textbf{r}.\\textbf{t}\\) Associative over scalar multiplication: \\(\\textbf{r}.(a \\textbf{s}) = a (\\textbf{r}.\\textbf{s})\\) \\[ \\textbf{r}.\\textbf{r} = \\sum_{i=1}^n r_i^2 = \\left(\\sqrt{\\sum_{i=1}^{n} r_i^2}\\right)^2 = |\\textbf{r}|^2 \\] i.e. the size of a vector is the square root of the dot product of the vector with itself. From the cosine rule : \\[ \\textbf{r}.\\textbf{s}=|\\textbf{r}||\\textbf{s}|\\cos \\theta \\] which tells us the extent to which the vectors go in the same direction. Therefore using the dot product, we can get the angle between the two vectors. If: \\(\\theta = 0^{\\circ}, \\cos \\theta = 1, \\therefore \\textbf{r}.\\textbf{s} = |\\textbf{r}||\\textbf{s}|\\) \\(\\theta = 90^{\\circ}, \\cos \\theta = 0, \\therefore \\textbf{r}.\\textbf{s} = 0\\) (vectors are orthogonal) \\(\\theta = 180^{\\circ}, \\cos \\theta = -1, \\therefore \\textbf{r}.\\textbf{s} = -|\\textbf{r}||\\textbf{s}|\\)","title":"Vectors"},{"location":"maths/linear-algebra/#scalar-projection","text":"Scalar projection of \\(\\textbf{s}\\) onto \\(\\textbf{r}\\) (how much \\(\\textbf{s}\\) goes along \\(\\textbf{r}\\) ): \\[ \\frac{\\textbf{r}.\\textbf{s}}{|\\textbf{r}|} = |\\textbf{s}| \\cos \\theta \\] The scalar projection is 0 if the vectors are orthogonal.","title":"Scalar Projection"},{"location":"maths/linear-algebra/#vector-projection","text":"\\[ \\textbf{r} \\frac{\\textbf{r}.\\textbf{s}}{|\\textbf{r}||\\textbf{r}|} = \\textbf{r} \\frac{\\textbf{r}.\\textbf{s}}{\\textbf{r}.\\textbf{r}} \\] which is the unit length vector \\(\\frac{\\textbf{r}}{|\\textbf{r}|} \\times\\) scalar projection of \\(\\textbf{s}\\) onto \\(\\textbf{r}\\) . The triangle inequality states that the sum of any two sides of a triangle must be greater than or equal to the size of the remaining side. For every pair of vectors \\(\\textbf{a}\\) and \\(\\textbf{b}\\) : \\[ |\\textbf{a}| + |\\textbf{b}| \\geq |\\textbf{a}+\\textbf{b}| \\]","title":"Vector Projection"},{"location":"reinforcement-learning/","text":"Key Ideas Reward Function Finite-horizon undiscounted return: \\[ R(\\tau)=\\sum_{t=0}^{T} r_{t} \\] Infinite-horizon discounted return: \\[ R(\\tau)=\\sum_{t=0}^{\\infty} \\gamma^{t} r_{t},\\quad \\gamma \\in(0,1) \\] Value Functions On-Policy Value Function: \\[ V^{\\pi}(s)=\\underset{\\tau \\sim \\pi}{\\mathbb{E}}\\left[R(\\tau) \\mid s_{0}=s\\right] \\] Bellman Equation Bellman Optimality Equation for state-action value function: \\[ q_*(s, a) = \\mathcal{R}^{a}_{s} + \\gamma \\sum_{s' \\in S}\\mathcal{P}^{a}_{ss'}\\max_{a'}q_*(s',a') \\] References OpenAI Spinning Up Documentation Part 1: Key Concepts in RL","title":"Key Ideas"},{"location":"reinforcement-learning/#key-ideas","text":"","title":"Key Ideas"},{"location":"reinforcement-learning/#reward-function","text":"Finite-horizon undiscounted return: \\[ R(\\tau)=\\sum_{t=0}^{T} r_{t} \\] Infinite-horizon discounted return: \\[ R(\\tau)=\\sum_{t=0}^{\\infty} \\gamma^{t} r_{t},\\quad \\gamma \\in(0,1) \\]","title":"Reward Function"},{"location":"reinforcement-learning/#value-functions","text":"On-Policy Value Function: \\[ V^{\\pi}(s)=\\underset{\\tau \\sim \\pi}{\\mathbb{E}}\\left[R(\\tau) \\mid s_{0}=s\\right] \\]","title":"Value Functions"},{"location":"reinforcement-learning/#bellman-equation","text":"Bellman Optimality Equation for state-action value function: \\[ q_*(s, a) = \\mathcal{R}^{a}_{s} + \\gamma \\sum_{s' \\in S}\\mathcal{P}^{a}_{ss'}\\max_{a'}q_*(s',a') \\]","title":"Bellman Equation"},{"location":"reinforcement-learning/#references","text":"OpenAI Spinning Up Documentation Part 1: Key Concepts in RL","title":"References"}]}